{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T15:28:11.467668Z",
     "start_time": "2020-12-17T15:27:55.132672Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def check_URL(input_string):\n",
    "    print(\"Welcome to IsItDown.py!\")\n",
    "    print(\"Please write a URL or URLs you want to check. (separated by comma)\")\n",
    "    li = input_string.replace(' ','').split(',')\n",
    "    li = ['http://'+i.lower() if 'http://' not in i.lower() else i for i in li ]\n",
    "    for site in li:\n",
    "        try:\n",
    "            if int(requests.get(site).status_code)//100 == 2: \n",
    "                print(f\"{site} is up!\")\n",
    "            else:\n",
    "                print(f\"{site} is down!\")\n",
    "        except:\n",
    "            print(f\"{site} is down!\")\n",
    "\n",
    "def answer():\n",
    "    repeat = input(\"Do you want to start over? y/n \")\n",
    "    if repeat == 'n':\n",
    "        return 0\n",
    "    elif repeat == 'y':\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Wrong Answer. again\")\n",
    "        return answer()\n",
    "            \n",
    "while True:\n",
    "    input_string = input()\n",
    "    check_URL(input_string)\n",
    "    if answer():\n",
    "        continue\n",
    "    else:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T14:10:52.411319Z",
     "start_time": "2020-12-19T14:10:41.402186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Please choose select a country by number:\n",
      "#0 Afghanistan\n",
      "#1 Åland islands\n",
      "#2 Albania\n",
      "#3 Algeria\n",
      "#4 American samoa\n",
      "#5 Andorra\n",
      "#6 Angola\n",
      "#7 Anguilla\n",
      "#8 Antigua and barbuda\n",
      "#9 Argentina\n",
      "#10 Armenia\n",
      "#11 Aruba\n",
      "#12 Australia\n",
      "#13 Austria\n",
      "#14 Azerbaijan\n",
      "#15 Bahamas (the)\n",
      "#16 Bahrain\n",
      "#17 Bangladesh\n",
      "#18 Barbados\n",
      "#19 Belarus\n",
      "#20 Belgium\n",
      "#21 Belize\n",
      "#22 Benin\n",
      "#23 Bermuda\n",
      "#24 Bhutan\n",
      "#25 Bhutan\n",
      "#26 Bolivia (plurinational state    of)\n",
      "#27 Bolivia (plurinational state    of)\n",
      "#28 Bonaire, sint eustatius and    saba\n",
      "#29 Bosnia and herzegovina\n",
      "#30 Botswana\n",
      "#31 Bouvet island\n",
      "#32 Brazil\n",
      "#33 British indian ocean    territory (the)\n",
      "#34 Brunei darussalam\n",
      "#35 Bulgaria\n",
      "#36 Burkina faso\n",
      "#37 Burundi\n",
      "#38 Cabo verde\n",
      "#39 Cambodia\n",
      "#40 Cameroon\n",
      "#41 Canada\n",
      "#42 Cayman islands (the)\n",
      "#43 Central african republic    (the)\n",
      "#44 Chad\n",
      "#45 Chile\n",
      "#46 Chile\n",
      "#47 China\n",
      "#48 Christmas island\n",
      "#49 Cocos (keeling) islands (the)\n",
      "#50 Colombia\n",
      "#51 Colombia\n",
      "#52 Comoros (the)\n",
      "#53 Congo (the democratic    republic of the)\n",
      "#54 Congo (the)\n",
      "#55 Cook islands (the)\n",
      "#56 Costa rica\n",
      "#57 Côte d'ivoire\n",
      "#58 Croatia\n",
      "#59 Cuba\n",
      "#60 Cuba\n",
      "#61 Curaçao\n",
      "#62 Cyprus\n",
      "#63 Czech republic (the)\n",
      "#64 Denmark\n",
      "#65 Djibouti\n",
      "#66 Dominica\n",
      "#67 Dominican republic (the)\n",
      "#68 Ecuador\n",
      "#69 Egypt\n",
      "#70 El salvador\n",
      "#71 El salvador\n",
      "#72 Equatorial guinea\n",
      "#73 Eritrea\n",
      "#74 Estonia\n",
      "#75 Ethiopia\n",
      "#76 European union\n",
      "#77 Falkland islands (the)    [malvinas]\n",
      "#78 Faroe islands (the)\n",
      "#79 Fiji\n",
      "#80 Finland\n",
      "#81 France\n",
      "#82 French guiana\n",
      "#83 French polynesia\n",
      "#84 French southern territories    (the)\n",
      "#85 Gabon\n",
      "#86 Gambia (the)\n",
      "#87 Georgia\n",
      "#88 Germany\n",
      "#89 Ghana\n",
      "#90 Gibraltar\n",
      "#91 Greece\n",
      "#92 Greenland\n",
      "#93 Grenada\n",
      "#94 Guadeloupe\n",
      "#95 Guam\n",
      "#96 Guatemala\n",
      "#97 Guernsey\n",
      "#98 Guinea\n",
      "#99 Guinea-bissau\n",
      "#100 Guyana\n",
      "#101 Haiti\n",
      "#102 Haiti\n",
      "#103 Heard island and mcdonald    islands\n",
      "#104 Holy see (the)\n",
      "#105 Honduras\n",
      "#106 Hong kong\n",
      "#107 Hungary\n",
      "#108 Iceland\n",
      "#109 India\n",
      "#110 Indonesia\n",
      "#111 International monetary fund    (imf) \n",
      "#112 Iran (islamic republic of)\n",
      "#113 Iraq\n",
      "#114 Ireland\n",
      "#115 Isle of man\n",
      "#116 Israel\n",
      "#117 Italy\n",
      "#118 Jamaica\n",
      "#119 Japan\n",
      "#120 Jersey\n",
      "#121 Jordan\n",
      "#122 Kazakhstan\n",
      "#123 Kenya\n",
      "#124 Kiribati\n",
      "#125 Korea (the democratic    people’s republic of)\n",
      "#126 Korea (the republic of)\n",
      "#127 Kuwait\n",
      "#128 Kyrgyzstan\n",
      "#129 Lao people’s democratic    republic (the)\n",
      "#130 Latvia\n",
      "#131 Lebanon\n",
      "#132 Lesotho\n",
      "#133 Lesotho\n",
      "#134 Liberia\n",
      "#135 Libya\n",
      "#136 Liechtenstein\n",
      "#137 Lithuania\n",
      "#138 Luxembourg\n",
      "#139 Macao\n",
      "#140 Republic of north macedonia\n",
      "#141 Madagascar\n",
      "#142 Malawi\n",
      "#143 Malaysia\n",
      "#144 Maldives\n",
      "#145 Mali\n",
      "#146 Malta\n",
      "#147 Marshall islands (the)\n",
      "#148 Martinique\n",
      "#149 Mauritania\n",
      "#150 Mauritius\n",
      "#151 Mayotte\n",
      "#152 Member countries of the    african development bank group\n",
      "#153 Mexico\n",
      "#154 Mexico\n",
      "#155 Micronesia (federated states    of)\n",
      "#156 Moldova (the republic of)\n",
      "#157 Monaco\n",
      "#158 Mongolia\n",
      "#159 Montenegro\n",
      "#160 Montserrat\n",
      "#161 Morocco\n",
      "#162 Mozambique\n",
      "#163 Myanmar\n",
      "#164 Namibia\n",
      "#165 Namibia\n",
      "#166 Nauru\n",
      "#167 Nepal\n",
      "#168 Netherlands (the)\n",
      "#169 New caledonia\n",
      "#170 New zealand\n",
      "#171 Nicaragua\n",
      "#172 Niger (the)\n",
      "#173 Nigeria\n",
      "#174 Niue\n",
      "#175 Norfolk island\n",
      "#176 Northern mariana islands    (the)\n",
      "#177 Norway\n",
      "#178 Oman\n",
      "#179 Pakistan\n",
      "#180 Palau\n",
      "#181 Panama\n",
      "#182 Panama\n",
      "#183 Papua new guinea\n",
      "#184 Paraguay\n",
      "#185 Peru\n",
      "#186 Philippines (the)\n",
      "#187 Pitcairn\n",
      "#188 Poland\n",
      "#189 Portugal\n",
      "#190 Puerto rico\n",
      "#191 Qatar\n",
      "#192 Réunion\n",
      "#193 Romania\n",
      "#194 Russian federation (the)\n",
      "#195 Rwanda\n",
      "#196 Saint barthélemy\n",
      "#197 Saint helena, ascension and    tristan da cunha\n",
      "#198 Saint kitts and nevis\n",
      "#199 Saint lucia\n",
      "#200 Saint martin (french part)\n",
      "#201 Saint pierre and miquelon\n",
      "#202 Saint vincent and the    grenadines\n",
      "#203 Samoa\n",
      "#204 San marino\n",
      "#205 Sao tome and principe\n",
      "#206 Saudi arabia\n",
      "#207 Senegal\n",
      "#208 Serbia\n",
      "#209 Seychelles\n",
      "#210 Sierra leone\n",
      "#211 Singapore\n",
      "#212 Sint maarten (dutch part)\n",
      "#213 Sistema unitario de    compensacion regional de pagos \"sucre\"\n",
      "#214 Slovakia\n",
      "#215 Slovenia\n",
      "#216 Solomon islands\n",
      "#217 Somalia\n",
      "#218 South africa\n",
      "#219 South sudan\n",
      "#220 Spain\n",
      "#221 Sri lanka\n",
      "#222 Sudan (the)\n",
      "#223 Suriname\n",
      "#224 Svalbard and jan mayen\n",
      "#225 Swaziland\n",
      "#226 Sweden\n",
      "#227 Switzerland\n",
      "#228 Switzerland\n",
      "#229 Switzerland\n",
      "#230 Syrian arab republic\n",
      "#231 Taiwan (province of china)\n",
      "#232 Tajikistan\n",
      "#233 Tanzania, united republic of\n",
      "#234 Thailand\n",
      "#235 Timor-leste\n",
      "#236 Togo\n",
      "#237 Tokelau\n",
      "#238 Tonga\n",
      "#239 Trinidad and tobago\n",
      "#240 Tunisia\n",
      "#241 Turkey\n",
      "#242 Turkmenistan\n",
      "#243 Turks and caicos islands    (the)\n",
      "#244 Tuvalu\n",
      "#245 Uganda\n",
      "#246 Ukraine\n",
      "#247 United arab emirates (the)\n",
      "#248 United kingdom of great    britain and northern ireland (the)\n",
      "#249 United states minor outlying    islands (the)\n",
      "#250 United states of america    (the)\n",
      "#251 United states of america    (the)\n",
      "#252 Uruguay\n",
      "#253 Uruguay\n",
      "#254 Uzbekistan\n",
      "#255 Vanuatu\n",
      "#256 Venezuela (bolivarian    republic of)\n",
      "#257 Viet nam\n",
      "#258 Virgin islands (british)\n",
      "#259 Virgin islands (u.s.)\n",
      "#260 Wallis and futuna\n",
      "#261 Western sahara\n",
      "#262 Yemen\n",
      "#263 Zambia\n",
      "#264 Zimbabwe\n",
      "Where are you from? Choose a country by number.\n",
      "\n",
      "#: 50\n",
      "Colombia\n",
      "\n",
      "Now choose another country.\n",
      "\n",
      "#: 126\n",
      "Korea (the republic of)\n",
      "\n",
      "\n",
      "How many COP do you want to convert to KRW?\n",
      "asdfsdfsd\n",
      "That wasn't a number.\n",
      "\n",
      "How many COP do you want to convert to KRW?\n",
      "5000000\n",
      "COP5,000,000.00 is ₩1,607,650.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.system(\"clear\")\n",
    "\n",
    "url = \"https://www.iban.com/currency-codes\"\n",
    "\n",
    "\n",
    "countries = []\n",
    "\n",
    "request = requests.get(url)\n",
    "soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\")\n",
    "rows = table.find_all(\"tr\")[1:]\n",
    "\n",
    "for row in rows:\n",
    "    items = row.find_all(\"td\")\n",
    "    name = items[0].text\n",
    "    code =items[2].text\n",
    "    if name and code:\n",
    "        if name != \"No universal currency\":\n",
    "            country = {\n",
    "                'name':name.capitalize(),\n",
    "                'code': code\n",
    "            }\n",
    "            countries.append(country)\n",
    "\n",
    "\n",
    "def ask():\n",
    "    try:\n",
    "        choice = int(input(\"#: \"))\n",
    "        if choice > len(countries):\n",
    "            print(\"Choose a number from the list.\")\n",
    "            ask()\n",
    "        else:\n",
    "            country = countries[choice]\n",
    "            print(f\"{country['name']}\\n\")\n",
    "    except ValueError:\n",
    "        print(\"That wasn't a number.\")\n",
    "        ask()\n",
    "    return country['code']\n",
    "\n",
    "def ask_convert():\n",
    "    print(f\"\\nHow many {country_a} do you want to convert to {country_b}?\")\n",
    "    money_input = input()\n",
    "    try:\n",
    "        money_input = float(money_input)\n",
    "    except:\n",
    "        print(\"That wasn't a number.\")\n",
    "        money_input = ask_convert()\n",
    "    return money_input\n",
    "\n",
    "def get_sym():\n",
    "    symbol_url = \"https://transferwise.com/gb/blog/world-currency-symbols\"\n",
    "\n",
    "    request = requests.get(symbol_url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    rows=[]\n",
    "    for table in tables:\n",
    "        rows.extend(table.find_all(\"tr\")[1:])\n",
    "\n",
    "    code_sym_dict=dict()\n",
    "\n",
    "    for row in rows:\n",
    "        items = row.find_all(\"td\")\n",
    "        code = items[2].text.strip()\n",
    "        sym =items[3].text.strip()\n",
    "        code_sym_dict[code] = sym\n",
    "    return code_sym_dict\n",
    "          \n",
    "def convert(money,sym):\n",
    "    rate_url = f\"https://transferwise.com/gb/currency-converter/{country_a.lower()}-to-{country_b.lower()}-rate\"\n",
    "    request = requests.get(rate_url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "    try:\n",
    "        result = money * float(soup.select(\"h3 > span.text-success\")[0].text)\n",
    "    except:\n",
    "          import pdb;pdb.set_trace()\n",
    "    print(f\"{country_a}{money:,.2f} is {sym}{result:,}\")\n",
    "\n",
    "                  \n",
    "print(\"Hello! Please choose select a country by number:\")\n",
    "for index, country in enumerate(countries):\n",
    "    print(f\"#{index} {country['name']}\")\n",
    "\n",
    "print(\"Where are you from? Choose a country by number.\\n\")\n",
    "\n",
    "country_a = ask()\n",
    "print('Now choose another country.\\n')\n",
    "country_b = ask()\n",
    "          \n",
    "code_sym_dict = get_sym()\n",
    "\n",
    "money = ask_convert()\n",
    "\n",
    "try:\n",
    "    sym = code_sym_dict[country_b]\n",
    "except:\n",
    "    sym = '$'\n",
    "\n",
    "convert(money,sym)\n",
    "\n",
    "## 나라랑 코드들을 받으면 유저가 2개의 나라를 선택하게 해.\n",
    "## 유저가 나라a 에서 나라b로 변환하고 싶은 통화 량을 선택하게 해\n",
    "## 2개의 화폐코드랑 양을 URL로 보내\n",
    "##beautiful soup사용해서 Transfer Wise에서 변환 결과확인해서 가져와."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://www.alba.co.kr/ 의 \n",
    "- ```html <ul class=\"goodBox\">``` 에서 아래와같은 컬럼 추출\n",
    "- place, title, time, pay, date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T16:56:58.146285Z",
     "start_time": "2020-12-21T16:56:25.950753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(주)신세계L&B csv 생성완료!\n",
      "아워홈 csv 생성완료!\n",
      "TGI FRIDAYS csv 생성완료!\n",
      "신선화로 csv 생성완료!\n",
      "트니트니 csv 생성완료!\n",
      "아티제 csv 생성완료!\n",
      "GS수퍼마켓 csv 생성완료!\n",
      "롯데리아 csv 생성완료!\n",
      "㈜이마트에브리데이 csv 생성완료!\n",
      "아웃백 csv 생성완료!\n",
      "홈플러스 익스프레스 csv 생성완료!\n",
      "딜리온 csv 생성완료!\n",
      "역전할머니맥주 csv 생성완료!\n",
      "(주)현대백화점 csv 생성완료!\n",
      "홍익아트 csv 생성완료!\n",
      "아소비 csv 생성완료!\n",
      "(주)우아한청년들 csv 생성완료!\n",
      "CU csv 생성완료!\n",
      "매머드커피 csv 생성완료!\n",
      "대한곱창 csv 생성완료!\n",
      "호치킨 csv 생성완료!\n",
      "이자녹스_비욘드_네이처컬렉션 csv 생성완료!\n",
      "코웨이 csv 생성완료!\n",
      "Bizit csv 생성완료!\n",
      "슈펜 csv 생성완료!\n",
      "윈윈파트너 csv 생성완료!\n",
      "엔제리너스 csv 생성완료!\n",
      "한국야쿠르트 csv 생성완료!\n",
      "대교 눈높이 csv 생성완료!\n",
      "iCOOP csv 생성완료!\n",
      "지오다노 csv 생성완료!\n",
      "써브웨이 csv 생성완료!\n",
      "웅진씽크빅 csv 생성완료!\n",
      "깐부치킨 csv 생성완료!\n",
      "버거킹 csv 생성완료!\n",
      "매드포갈릭 csv 생성완료!\n",
      "성원아이북랜드 csv 생성완료!\n",
      "자라코리아 csv 생성완료!\n",
      "마왕족발 csv 생성완료!\n",
      "아이스크림홈런 csv 생성완료!\n",
      "맘시터 csv 생성완료!\n",
      "SSG.COM csv 생성완료!\n",
      "기탄사고력교실 csv 생성완료!\n",
      "경복궁 csv 생성완료!\n",
      "메가마트 csv 생성완료!\n",
      "에잇세컨즈 csv 생성완료!\n",
      "㈜이마트 csv 생성완료!\n",
      "엔타스 csv 생성완료!\n",
      "㈜호텔신라 csv 생성완료!\n",
      "딜버 csv 생성완료!\n",
      "세븐일레븐 csv 생성완료!\n",
      "SK에너지 csv 생성완료!\n",
      "쉐이크쉑 csv 생성완료!\n",
      "피자샵 csv 생성완료!\n",
      "호식이두마리치킨 csv 생성완료!\n",
      "제이디스포츠패션코리아 csv 생성완료!\n",
      "한경기획 csv 생성완료!\n",
      "(주)교원구몬 csv 생성완료!\n",
      "하남돼지집 csv 생성완료!\n",
      "빨간모자피자 csv 생성완료!\n",
      "7번가피자 csv 생성완료!\n",
      "한솔교육 csv 생성완료!\n",
      "(주)에이비씨마트코리아 csv 생성완료!\n",
      "엠즈씨드 csv 생성완료!\n",
      "(주)신세계 csv 생성완료!\n",
      "롤링핀 csv 생성완료!\n",
      "(주)농협유통 csv 생성완료!\n",
      "스타벅스커피 코리아 csv 생성완료!\n",
      "GS25 csv 생성완료!\n",
      "KFC csv 생성완료!\n",
      "신세계푸드 csv 생성완료!\n",
      "배달대행 런닝맨 csv 생성완료!\n",
      "(주)후니에프앤비 csv 생성완료!\n",
      "사보텐 & 타코벨 csv 생성완료!\n",
      "유니클로 csv 생성완료!\n",
      "슈마커 csv 생성완료!\n",
      "파리크라상 외식사업부 csv 생성완료!\n",
      "크리스피 크림 도넛 csv 생성완료!\n",
      "도미노 피자 csv 생성완료!\n",
      "메쉬코리아 csv 생성완료!\n",
      "또봉이통닭 csv 생성완료!\n",
      "롯데쇼핑㈜ H&B사업본부 (롭스) csv 생성완료!\n",
      "일미리금계찜닭 csv 생성완료!\n",
      "백종원의 더본코리아 직,가맹점 csv 생성완료!\n",
      "(주)하이엠솔루텍 csv 생성완료!\n",
      "교촌치킨 csv 생성완료!\n",
      "경성주막 & 크라운호프 & 금복주류 csv 생성완료!\n",
      "닭장수후라이드 和 csv 생성완료!\n",
      "㈜초록마을 csv 생성완료!\n",
      "커피스미스 csv 생성완료!\n",
      "(주)바로고 csv 생성완료!\n",
      "미니스톱 csv 생성완료!\n",
      "(주)노랑푸드 노랑통닭 csv 생성완료!\n",
      "노브랜드 csv 생성완료!\n",
      "ELAND FASHION csv 생성완료!\n",
      "당신의집사 csv 생성완료!\n",
      "할리스커피 & 디초콜릿커피앤드 csv 생성완료!\n",
      "풀무원녹즙 csv 생성완료!\n",
      "째깍악어 csv 생성완료!\n",
      "(주)대연-나이키공식판매점 csv 생성완료!\n",
      "GS리테일 H&B사업부문(랄라블라) csv 생성완료!\n",
      "러쉬코리아 csv 생성완료!\n",
      "장원교육 csv 생성완료!\n",
      "다이소 csv 생성완료!\n",
      "생활맥주 csv 생성완료!\n",
      "두발히어로 csv 생성완료!\n",
      "또래오래 csv 생성완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_super_brand(url):\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "    ## 슈퍼브랜드 li a태그 가져오기\n",
    "    MainSuperBrand = soup.find('div',id='MainSuperBrand')\n",
    "    ul = MainSuperBrand.find('ul',class_='goodsBox')\n",
    "    superBrand_list = ul.find_all('li')\n",
    "\n",
    "    superBrand_list = superBrand_list[:-1]\n",
    "\n",
    "    href_list = []\n",
    "    for superBrand in superBrand_list:\n",
    "        company_name = superBrand.find('span',{'class':'company'}).text\n",
    "        link = superBrand.a['href']\n",
    "        href_list.append({'company':company_name,'link':link})\n",
    "    return href_list\n",
    "\n",
    "def get_table_row_li(super_brand_url):\n",
    "    try:\n",
    "        response = requests.get(super_brand_url['link'])\n",
    "    except:\n",
    "        import pdb;pdb.set_trace()\n",
    "\n",
    "    super_brand_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    ## place, title, time, pay, date\n",
    "    NormalInfo = super_brand_soup.find('div', id='NormalInfo')\n",
    "    table = NormalInfo.find('tbody')\n",
    "    tr_li = table.find_all('tr')\n",
    "    return super_brand_url['company'],tr_li\n",
    "    \n",
    "\n",
    "    \n",
    "def get_job_info(table_row_li):\n",
    "    brand_li=list()\n",
    "    tr_li = table_row_li\n",
    "    for tr in tr_li[::2]:\n",
    "        try:\n",
    "            place = tr.find('td',{'class':'local first'}).text.replace(u'\\xa0', u' ')\n",
    "        except:\n",
    "            import pdb;pdb.set_trace()\n",
    "        title = tr.find('td',{'class':'title'}).find('span',{'class':'company'}).text.strip()\n",
    "        time = tr.find('td',{'class':'data'}).text\n",
    "        pay = tr.find('td',{'class':'pay'}).text\n",
    "        date = tr.find('td',{'class':'regDate last'}).text\n",
    "        brand_li.append({'place':place, 'title':title, 'time':time,'pay':pay,'date':date})\n",
    "    return brand_li\n",
    "\n",
    "os.system(\"clear\")\n",
    "alba_url = \"http://www.alba.co.kr\"\n",
    "\n",
    "href_list = get_super_brand(alba_url)\n",
    "for one_company in href_list:\n",
    "    company_name, table_row_li = get_table_row_li(one_company)\n",
    "    if len(table_row_li) == 1:\n",
    "        continue\n",
    "    brand_li =  get_job_info(table_row_li)\n",
    "    company_name = company_name.replace('/','_')\n",
    "    pd.DataFrame(brand_li)[['place','title','time','pay','date']].to_csv(f'{company_name}.csv',index=False)\n",
    "    print(f\"{company_name} csv 생성완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 8-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T15:57:55.329157Z",
     "start_time": "2020-12-23T15:56:41.618611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"DayNine\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [24/Dec/2020 00:56:51] \"\u001b[37mGET /25518757 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Dec/2020 00:56:54] \"\u001b[37mGET /?order_by=popular HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Dec/2020 00:56:59] \"\u001b[37mGET /16582136 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [24/Dec/2020 00:57:32] \"\u001b[37mGET /11116274 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flask import Flask, render_template, request\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"http://hn.algolia.com/api/v1\"\n",
    "\n",
    "# This URL gets the newest stories.\n",
    "new = f\"{base_url}/search_by_date?tags=story\"\n",
    "\n",
    "# This URL gets the most popular stories\n",
    "popular = f\"{base_url}/search?tags=story\"\n",
    "\n",
    "def extract_json(order_by):\n",
    "    page={}\n",
    "    r_page = requests.get(order_by)\n",
    "    for r in r_page.json()['hits']:\n",
    "        page.update({r['objectID'] : {'num_comments' : r['num_comments'],\n",
    "                    'author' : r['author'],\n",
    "                    'points' : r['points'],\n",
    "                    'title' : r['title'],\n",
    "                    'url' : r['url'],\n",
    "                    'objectID' : r['objectID']\n",
    "                    }})\n",
    "    return page\n",
    "\n",
    "# This function makes the URL to get the detail of a storie by id.\n",
    "# Heres the documentation: https://hn.algolia.com/api\n",
    "def make_detail_url(id):\n",
    "    return f\"{base_url}/items/{id}\"\n",
    "\n",
    "new_page_di = extract_json(new)\n",
    "new_page_li = list(new_page_di.values())\n",
    "popular_page_di = extract_json(popular)\n",
    "popular_page_li = list(popular_page_di.values())\n",
    "\n",
    "app = Flask(\"DayNine\")\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home(**kwargs):\n",
    "    order_by = request.args.get('order_by')\n",
    "    if order_by:\n",
    "        if order_by=='new':\n",
    "            return render_template('order_new.html',page_li=new_page_li)\n",
    "        elif order_by=='popular':\n",
    "            \n",
    "            return render_template('index.html',page_li=popular_page_li)\n",
    "    else:\n",
    "        return render_template('index.html')\n",
    "\n",
    "@app.route(\"/<id>\")\n",
    "def go_id_page(id):\n",
    "    if id in new_page_di.keys():\n",
    "        news = new_page_di[str(id)]\n",
    "    elif id in popular_page_di.keys():\n",
    "        news = popular_page_di[str(id)]\n",
    "    comment_url = make_detail_url(id)\n",
    "    comment_page = requests.get(comment_url)\n",
    "    df = pd.DataFrame(comment_page.json()['children'])\n",
    "    df_comment = df[df.author.notna()][['author','text']]\n",
    "    return render_template('detail.html', df=df_comment, news=news)\n",
    "\n",
    "# @app.route(\"/?order_by=popular\")\n",
    "# def order_popular():\n",
    "#     return render_template(\"index.html\")\n",
    "\n",
    "app.run(host=\"0.0.0.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
